---
# yaml-language-server: $schema=schemas/page_dasboard.schema.json
Object type:
    - Page/Dasboard
Backlinks:
    - Blog
Creation date: "2025-11-17T21:01:17Z"
Created by:
    - Jamie Forrest
id: bafyreianjecnpaxgmz6ujvvbmtbv3hlqt3veribxqir5vqzpt5go33a6ie
---
# When Seeing Is No Longer Believing: Deepfakes as a Public Health Crisis   
On a cold January morning in 2024, a finance worker in Hong Kong received what appeared to be a routine video call from her company's chief financial officer. The face on the screen was familiar, the voice reassuring, the request straightforward: authorize a $25 million transaction. She complied without hesitation. The person she trusted was, after all, right there on her screen—or so she thought. Within hours, the devastating truth emerged: every face on that call, every voice, every reassuring gesture had been fabricated using deepfake technology. The $25 million was gone, transferred to criminals who had weaponized artificial intelligence to manufacture reality itself.[cnn](https://www.cnn.com/2024/05/16/tech/arup-deepfake-scam-loss-hong-kong-intl-hnk)   
This isn't science fiction. This is the world we inhabit today—a world where the boundary between authentic and artificial has become dangerously blurred, where trust itself has become a vulnerability, and where the implications extend far beyond financial fraud into the realm of public health.   
1. [https://www.cnn.com/2024/05/16/tech/arup-deepfake-scam-loss-hong-kong-intl-hnk](https://www.cnn.com/2024/05/16/tech/arup-deepfake-scam-loss-hong-kong-intl-hnk)   
   
When Dr. François Marquis, chief of intensive care at Maisonneuve-Rosemont Hospital in Montreal, discovered his face and voice being used to sell fraudulent health products online, his first thought wasn't about his own reputation. "My primary worry is for the individuals who trust me," he explained to reporters. "It's putting a lot of damage on all physicians in Quebec and in Canada". Dr. Marquis had become an unwitting participant in a new frontier of health misinformation—one where artificial intelligence doesn't just spread false information, but manufactures credible spokespersons to deliver it.[cbc](https://www.cbc.ca/news/canada/montreal/quebec-doctors-deepfake-scams-warning-1.7599117)   
His experience is far from isolated. Dr. Alain Vadeboncoeur of the Montreal Heart Institute found himself digitally cloned across multiple deepfake videos discussing urology, prostate cancer, and sexual dysfunction—subjects entirely outside his medical specialty. "The danger is you don't know what it is that they're taking," Dr. Marquis warned, highlighting how even seemingly harmless supplements could trigger adverse reactions or, worse, convince patients to abandon proven treatments like insulin or anticoagulants for counterfeit alternatives.[cbc](https://www.cbc.ca/news/canada/montreal/quebec-doctors-deepfake-scams-warning-1.7599117)   
These cases illuminate a critical evolution in the infodemic landscape. During the COVID-19 pandemic, the World Health Organization warned of an unprecedented "infodemic"—an overabundance of information, both accurate and false, that made it difficult for people to find trustworthy guidance when they needed it most. But deepfakes represent something qualitatively different: not just the spread of misinformation, but the systematic erosion of our ability to determine what is real at all.[hhs](https://www.hhs.gov/sites/default/files/surgeon-general-misinformation-advisory.pdf)   
1. [https://www.cbc.ca/news/canada/montreal/quebec-doctors-deepfake-scams-warning-1.7599117](https://www.cbc.ca/news/canada/montreal/quebec-doctors-deepfake-scams-warning-1.7599117)   
2. [https://www.hhs.gov/sites/default/files/surgeon-general-misinformation-advisory.pdf](https://www.hhs.gov/sites/default/files/surgeon-general-misinformation-advisory.pdf)   
   
The health impacts of deepfakes extend far beyond misguided medical decisions. When we examine the psychological consequences documented in clinical research, we find a cascade of harm that rivals physical assault in its severity and duration.   
Consider the mental health outcomes reported by victims of image-based sexual abuse using deepfake technology. Research consistently documents rates of depression, anxiety, and post-traumatic stress disorder comparable to those seen in survivors of physical violence. "Being victimized through deepfakes can erase your sense of reality," explains therapist Francesca Rossi, who specializes in treating survivors of this form of abuse. The dissonance between knowing the imagery is fabricated while watching it look utterly convincing creates a profound psychological rupture.[edition.cnn+1](https://edition.cnn.com/2025/01/02/health/deepfakes-social-media-wellness)   
For children and adolescents, the stakes are even higher. The American Academy of Pediatrics reports that young victims of deepfake pornography experience humiliation, shame, violation, and self-blame that can lead to immediate emotional distress, withdrawal from school and family, and in severe cases, self-harm and suicidal ideation. The European Parliament notes that mental health impacts can be "just as severe as that of real content," causing anxiety, depression, and sometimes post-traumatic stress disorder. One in six minors who experience potentially harmful online sexual interactions never disclose it to anyone, with boys even less likely to seek help—intensifying their isolation and suffering.[europarl.europa+1](https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/775855/EPRS_BRI(2025)775855_EN.pdf)   
The trauma extends to healthcare workers themselves. A study of Romanian frontline medical staff during the COVID-19 pandemic found that clinicians who reported being affected by false news in their professional activities experienced significantly higher levels of stress, anxiety, and insomnia than their colleagues who felt insulated from the infodemic. These healthcare workers described feeling emotionally overwhelmed by fake news and reported that misinformation damaged the doctor-patient relationship, with patients increasingly distrusting their physicians.[pmc.ncbi.nlm.nih](https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/)   
1. [https://edition.cnn.com/2025/01/02/health/deepfakes-social-media-wellness](https://edition.cnn.com/2025/01/02/health/deepfakes-social-media-wellness)   
2. [https://mashable.com/article/explicit-deepfake-mental-health-recovery](https://mashable.com/article/explicit-deepfake-mental-health-recovery)   
3. [https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/775855/EPRS\_BRI(2025)775855\_EN.pdf](https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/775855/EPRS_BRI(2025)775855_EN.pdf)   
4. [https://www.aap.org/en/patient-care/media-and-children/center-of-excellence-on-social-media-and-youth-mental-health/qa-portal/qa-portal-library/qa-portal-library-questions/the-impact-of-deepfakes-synthetic-pornography--virtual-child-sexual-abuse-material/](https://www.aap.org/en/patient-care/media-and-children/center-of-excellence-on-social-media-and-youth-mental-health/qa-portal/qa-portal-library/qa-portal-library-questions/the-impact-of-deepfakes-synthetic-pornography--virtual-child-sexual-abuse-material/)   
5. [https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/)   
   
The threat deepfakes pose to public health extends beyond individual psychological trauma to systemic failures in emergency response and community health.   
During the COVID-19 pandemic, health misinformation about vaccines, treatments, and preventive measures spread with viral efficiency across social media platforms. Analysis of Facebook posts found that approximately 46.6% of vaccine-related content contained misinformation, while fact-checking posts represented only 47.4% of the conversation—and 28.5% of those fact-checks actually repeated the false claims they were trying to correct. A study tracking COVID-19 misinformation in 87 countries during the first three months of 2020 found that the infodemic resulted in over 5,800 hospitalizations and hundreds of deaths directly linked to conspiracy theories and false information.[researchpartnership+1](https://www.researchpartnership.com/insights/fake-news-pandemic-the-rise-of-healthcare-misinformation-in-the-age-of-covid-19/)   
Deepfakes threaten to exponentially amplify this problem. While traditional misinformation could be produced and shared by anyone, deepfakes carry the manufactured authority of trusted experts. Imagine a deepfake video of Dr. Anthony Fauci or the CDC Director promoting ivermectin or discouraging vaccination, distributed during a critical phase of pandemic response. The consequences could be catastrophic.   
The World Economic Forum has identified disinformation as one of the top global risks for 2024, with deepfakes ranked as one of the most worrying uses of AI. With deepfake incidents increasing from just 22 between 2017-2022 to 179 in the first quarter of 2025 alone—a 19% increase over all of 2024—we are witnessing an acceleration that outpaces nearly every other cyber threat.[keepnetlabs+2](https://keepnetlabs.com/blog/deepfake-statistics-and-trends)   
Vulnerable populations bear disproportionate risk. Research on deepfakes in resource-limited communities reveals critical knowledge gaps and a lack of effective detection tools. Marginalized communities, already facing systemic barriers to healthcare and experiencing lower levels of institutional trust due to historical discrimination, may be particularly susceptible to deepfake-enabled health misinformation. The elderly, who report $3.4 billion in fraud losses in 2023, face special vulnerability to sophisticated AI-generated scams.[arxiv+2](https://arxiv.org/html/2508.16618v1)   
To combat deepfakes effectively, we must understand how they work. At their core, most deepfakes are created using Generative Adversarial Networks (GANs)—a type of artificial intelligence introduced in 2014 that pits two neural networks against each other in a competitive process. One network, the "generator," creates fake content, while the other, the "discriminator," tries to detect whether the content is real or fabricated. Through millions of iterations, the generator becomes increasingly skilled at fooling the discriminator, producing hyper-realistic synthetic media.[journals.acspublisher+1](https://www.journals.acspublisher.com/index.php/dbitdjr/article/download/20696/17948/35222)   
1. [https://www.researchpartnership.com/insights/fake-news-pandemic-the-rise-of-healthcare-misinformation-in-the-age-of-covid-19/](https://www.researchpartnership.com/insights/fake-news-pandemic-the-rise-of-healthcare-misinformation-in-the-age-of-covid-19/)   
2. [https://misinforeview.hks.harvard.edu/article/the-battleground-of-covid-19-vaccine-misinformation-on-facebook-fact-checkers-vs-misinformation-spreaders/](https://misinforeview.hks.harvard.edu/article/the-battleground-of-covid-19-vaccine-misinformation-on-facebook-fact-checkers-vs-misinformation-spreaders/)   
3. [https://keepnetlabs.com/blog/deepfake-statistics-and-trends](https://keepnetlabs.com/blog/deepfake-statistics-and-trends)   
4. [https://surfshark.com/research/study/deepfake-statistics](https://surfshark.com/research/study/deepfake-statistics)   
5. [https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/](https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/)   
6. [https://arxiv.org/html/2508.16618v1](https://arxiv.org/html/2508.16618v1)   
7. [https://www.brookings.edu/articles/the-threat-posed-by-deepfakes-to-marginalized-communities/](https://www.brookings.edu/articles/the-threat-posed-by-deepfakes-to-marginalized-communities/)   
   
What once required extensive technical expertise and significant computing power can now be accomplished with widely available tools costing less than $400 per month. The accessibility of these technologies means that malicious actors—from individual scammers to state-sponsored disinformation campaigns—can produce convincing deepfakes at scale.[weforum](https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/)   
The technology continues to advance at a startling pace. Modern deepfakes can manipulate not just images and video, but audio as well, with voice cloning possible from as little as 15 seconds of authentic audio. Research tracking deepfake technology in 2024 found that many academic detection systems have become outdated, unable to identify the latest manipulation techniques circulating on social media.[arxiv+1](https://arxiv.org/html/2503.02857v2)   
1. [https://www.journals.acspublisher.com/index.php/dbitdjr/article/download/20696/17948/35222](https://www.journals.acspublisher.com/index.php/dbitdjr/article/download/20696/17948/35222)   
2. [https://www.ebsco.com/research-starters/computer-science/deepfake](https://www.ebsco.com/research-starters/computer-science/deepfake)   
3. [https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/](https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/)   
4. [https://arxiv.org/html/2503.02857v2](https://arxiv.org/html/2503.02857v2)   
5. [https://www.teneo.com/insights/articles/deepfakes-in-2024-are-suddenly-deeply-real-an-executive-briefing-on-the-threat-and-trends/](https://www.teneo.com/insights/articles/deepfakes-in-2024-are-suddenly-deeply-real-an-executive-briefing-on-the-threat-and-trends/)   
   
The deepfake crisis forces us to confront a fundamental challenge to what security experts call "cognitive security"—the protection of human cognitive processes from manipulation and the integrity of information ecosystems. In healthcare contexts, where accurate information can mean the difference between life and death, cognitive security becomes a matter of survival.[yorkspace.library.yorku+1](https://yorkspace.library.yorku.ca/bitstreams/f82a16e0-41eb-4387-9517-dcc5277027c1/download)   
The concept of "information integrity"—the consistency, reliability, accuracy, fidelity, safety, and transparency of an information ecosystem—provides a framework for understanding what's at stake. When deepfakes proliferate, they don't just spread individual pieces of false information; they undermine the entire foundation of trust that makes public health communication possible.[carnegieendowment](https://carnegieendowment.org/research/2023/11/emergency-management-and-information-integrity-a-framework-for-crisis-response?lang=en)   
This erosion of trust has cascading effects. Canadian physicians report that health misinformation leads patients to refuse established treatments, resulting in severe consequences including preventable deaths. During COVID-19, vaccine hesitancy driven by misinformation was directly linked to continued disease transmission, with one study finding that exposure to online misinformation about vaccines reduced vaccination intent by 6.4 percentage points in the US and 6.2 percentage points in the UK.[cbc+1](https://www.cbc.ca/news/health/medical-misinformation-cma-1.7630741)   
Emergency management experts warn that deepfakes pose unique challenges for crisis response. "Deepfakes strike at the heart of what emergency managers and homeland security professionals rely on: clear, trusted, timely communication," notes a recent analysis of deepfake threats to emergency management. A fabricated video of a mayor announcing an evacuation, a synthetic voice impersonating a trusted official—these aren't hypothetical scenarios but plausible attack vectors in our current information environment.[hstoday](https://www.hstoday.us/featured/perspective-deepfakes-and-the-erosion-of-trust-in-homeland-security/)   
1. [https://yorkspace.library.yorku.ca/bitstreams/f82a16e0-41eb-4387-9517-dcc5277027c1/download](https://yorkspace.library.yorku.ca/bitstreams/f82a16e0-41eb-4387-9517-dcc5277027c1/download)   
2. [https://blackbird.ai/blog/what-is-cognitive-security/](https://blackbird.ai/blog/what-is-cognitive-security/)   
3. [https://carnegieendowment.org/research/2023/11/emergency-management-and-information-integrity-a-framework-for-crisis-response?lang=en](https://carnegieendowment.org/research/2023/11/emergency-management-and-information-integrity-a-framework-for-crisis-response?lang=en)   
4. [https://www.cbc.ca/news/health/medical-misinformation-cma-1.7630741](https://www.cbc.ca/news/health/medical-misinformation-cma-1.7630741)   
5. [https://www.nature.com/articles/s41598-022-17430-6](https://www.nature.com/articles/s41598-022-17430-6)   
6. [https://www.hstoday.us/featured/perspective-deepfakes-and-the-erosion-of-trust-in-homeland-security/](https://www.hstoday.us/featured/perspective-deepfakes-and-the-erosion-of-trust-in-homeland-security/)   
   
Confronting the deepfake crisis requires coordination across multiple levels—technological, regulatory, educational, and community-based.   
**Detection and Authentication Technologies**   
On the technological front, significant progress has been made in developing detection systems. Machine learning algorithms can analyze digital content for inconsistencies associated with deepfakes, examining subtle irregularities in facial movements, lighting, audio synchronization, and compression artifacts. Companies like Google have developed watermarking systems such as SynthID, which embed invisible markers in AI-generated content to indicate its artificial origin. The Coalition for Content Provenance and Authenticity (C2PA) framework, supported by Adobe, Microsoft, and other major tech companies, embeds tamper-proof metadata into images and videos, enabling traceability of content origin.[mdpi+3](https://www.mdpi.com/2073-431X/12/10/216/pdf?version=1698110469)   
However, these technological solutions face significant challenges. Deepfake creators continually develop new techniques to evade detection, creating what observers describe as a "virtual arms race". Watermarks can be removed through adversarial attacks, and detection systems trained on existing datasets may fail to identify novel manipulation techniques. Moreover, these tools are often inaccessible to those who need them most—marginalized communities, elderly individuals, and people in resource-limited settings.[arxiv+3](https://arxiv.org/html/2508.16618v1)   
**Regulatory and Policy Responses**   
On the regulatory front, governments worldwide are grappling with how to address deepfakes without infringing on free speech or innovation. As of 2024, six US states had passed laws specifically targeting deepfake election interference, while legislation in seven other states had stalled. China has taken a more aggressive approach, implementing regulations in 2023 that require labeling of AI-generated content and prohibit the creation of deepfakes that could disrupt economic or national security.[ebsco+1](https://www.ebsco.com/research-starters/computer-science/deepfake)   
The challenge lies in achieving international coordination. Deepfakes recognize no borders, and effective regulation requires consensus on definitions, ethical standards, and enforcement mechanisms. The European Union's AI Act, approved in 2024, mandates disclosure when users interact with AI-generated content, representing one step toward transparency.[weforum+1](https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/)   
**Digital Literacy and Prebunking**   
Perhaps the most promising avenue for building societal resilience lies in educational interventions—specifically, approaches based on "inoculation theory" that "prebunk" rather than debunk misinformation.[misinforeview.hks.harvard+1](https://misinforeview.hks.harvard.edu/wp-content/uploads/2020/02/FORMATTED_globalvaccination_Jan30.pdf)   
Traditional fact-checking and debunking efforts face inherent limitations: they're reactive, difficult to scale, and can actually reinforce false beliefs through the "continued influence effect". Inoculation theory offers an alternative. Just as medical vaccines expose the body to weakened pathogens to build immunity, psychological "prebunking" exposes people to weakened examples of manipulation techniques, helping them develop "mental antibodies" against misinformation.[doaj+1](https://doaj.org/article/4dfdc9e880d342e098921d3460a95502)   
Research demonstrates the effectiveness of this approach. A large-scale study of the "Bad News" game—an online intervention that teaches people to recognize common misinformation techniques—found significant reductions in susceptibility to false content across multiple countries and cultures. Participants' ability to identify manipulative content improved by approximately 26.5% in the United States and 17.5% in India. Crucially, these effects persisted over time and transferred across different topics, suggesting that people were learning generalizable skills rather than just memorizing specific false claims.[pnas+1](https://www.pnas.org/doi/10.1073/pnas.1920498117)   
Digital literacy interventions show particular promise for older adults, a demographic often identified as vulnerable to misinformation. A study of adults over 60 found that a one-hour, self-directed digital literacy intervention significantly improved their ability to discern fake from true news, from 64% accuracy before the intervention to 85% afterward.[nature](https://www.nature.com/articles/s41598-022-08437-0)   
**Trusted Messengers and Community Engagement**   
Public health research consistently identifies the critical role of trusted messengers in combating health misinformation. During emergencies, people are more likely to adopt protective health behaviors when information comes from sources they trust—and that trust is often rooted in shared identity, lived experience, and consistent community engagement rather than institutional authority alone.[who+1](https://www.who.int/europe/news/item/09-12-2024-trusted-messengers--community-anchors-and-agents-of-change--engaging-health-and-care-workers-in-times-of-crisis)   
Community-based organizations (CBOs) and community health workers serve as vital bridges between healthcare systems and communities, especially those experiencing historical marginalization or institutional mistrust. These trusted messengers speak the same language, understand local cultural contexts, and have earned credibility through sustained presence and service. During COVID-19, community health workers played essential roles in vaccine outreach, myth-busting, and ensuring access to accurate health information.[pmc.ncbi.nlm.nih+1](https://pmc.ncbi.nlm.nih.gov/articles/PMC10939007/)   
Healthcare workers themselves function as trusted messengers, though the infodemic places them in a challenging position. The WHO emphasizes that health and care workers are "not just caregivers, but also trusted messengers, community anchors and agents of change". Supporting healthcare workers with training in risk communication, infodemic management, and tools for countering misinformation becomes critical—as does protecting their mental health and wellbeing as they navigate the dual burdens of clinical care and information warfare.[pmc.ncbi.nlm.nih+1](https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/)   
**The WHO Framework for Infodemic Management**   
The World Health Organization has developed a comprehensive framework for infodemic management, built around five key action areas:[pmc.ncbi.nlm.nih+2](https://pmc.ncbi.nlm.nih.gov/articles/PMC8448461/)   
1. **Listening to community concerns and questions** through systematic social listening and feedback mechanisms   
2. **Promoting understanding of risk and health expert advice** through clear, evidence-based communication   
3. **Building resilience to misinformation** through education and digital literacy interventions   
4. **Engaging and empowering communities** to take positive action   
5. **Strengthening systems** for infodemic management in health emergencies   
   
This framework recognizes that managing infodemics requires coordinated, multi-sectoral action sustained throughout the emergency lifecycle—before, during, and after acute crises. It emphasizes the importance of risk communication that is transparent about scientific uncertainty, culturally tailored to diverse communities, and delivered through channels and messengers that communities trust.[pmc.ncbi.nlm.nih+2](https://pmc.ncbi.nlm.nih.gov/articles/PMC7332158/)   
Critically, the framework advocates for proactive rather than purely reactive approaches. South Africa's experience during COVID-19 demonstrates the value of systematic social listening, where local public health officers completed weekly reports based on grassroots community interactions, providing real-time data on public sentiment, rumors, and information needs. This bottom-up intelligence informed policy decisions and communication strategies, ensuring that public health responses addressed actual community concerns rather than operating on assumptions.[pmc.ncbi.nlm.nih](https://pmc.ncbi.nlm.nih.gov/articles/PMC11933818/)   
1. [https://www.mdpi.com/2073-431X/12/10/216/pdf?version=1698110469](https://www.mdpi.com/2073-431X/12/10/216/pdf?version=1698110469)   
2. [https://www.cyberpeace.org/resources/blogs/watermarking-standards-and-policy-for-ai-generated-media](https://www.cyberpeace.org/resources/blogs/watermarking-standards-and-policy-for-ai-generated-media)   
3. [https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/](https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/)   
4. [https://deepmind.google/models/synthid/](https://deepmind.google/models/synthid/)   
5. [https://arxiv.org/html/2508.16618v1](https://arxiv.org/html/2508.16618v1)   
6. [https://www.brookings.edu/articles/the-threat-posed-by-deepfakes-to-marginalized-communities/](https://www.brookings.edu/articles/the-threat-posed-by-deepfakes-to-marginalized-communities/)   
7. [https://www.ebsco.com/research-starters/computer-science/deepfake](https://www.ebsco.com/research-starters/computer-science/deepfake)   
8. [https://ised-isde.canada.ca/site/ised/en/canadian-artificial-intelligence-safety-institute/research-agenda-risks-synthetic-content](https://ised-isde.canada.ca/site/ised/en/canadian-artificial-intelligence-safety-institute/research-agenda-risks-synthetic-content)   
9. [https://www.teneo.com/insights/articles/deepfakes-in-2024-are-suddenly-deeply-real-an-executive-briefing-on-the-threat-and-trends/](https://www.teneo.com/insights/articles/deepfakes-in-2024-are-suddenly-deeply-real-an-executive-briefing-on-the-threat-and-trends/)   
10. [https://infodemiology.jmir.org/2025/1/e69474](https://infodemiology.jmir.org/2025/1/e69474)   
11. [https://misinforeview.hks.harvard.edu/wp-content/uploads/2020/02/FORMATTED\_globalvaccination\_Jan30.pdf](https://misinforeview.hks.harvard.edu/wp-content/uploads/2020/02/FORMATTED_globalvaccination_Jan30.pdf)   
12. [https://www.cam.ac.uk/stories/inoculateexperiment](https://www.cam.ac.uk/stories/inoculateexperiment)   
13. [https://doaj.org/article/4dfdc9e880d342e098921d3460a95502](https://doaj.org/article/4dfdc9e880d342e098921d3460a95502)   
14. [https://www.pnas.org/doi/10.1073/pnas.1920498117](https://www.pnas.org/doi/10.1073/pnas.1920498117)   
15. [https://www.nature.com/articles/s41598-022-08437-0](https://www.nature.com/articles/s41598-022-08437-0)   
16. [https://www.who.int/europe/news/item/09-12-2024-trusted-messengers--community-anchors-and-agents-of-change--engaging-health-and-care-workers-in-times-of-crisis](https://www.who.int/europe/news/item/09-12-2024-trusted-messengers--community-anchors-and-agents-of-change--engaging-health-and-care-workers-in-times-of-crisis)   
17. [https://pmc.ncbi.nlm.nih.gov/articles/PMC10939007/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10939007/)   
18. [https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7763025/)   
19. [https://pmc.ncbi.nlm.nih.gov/articles/PMC8448461/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8448461/)   
20. [https://infodemiology.jmir.org/2021/1/e30979/PDF](https://infodemiology.jmir.org/2021/1/e30979/PDF)   
21. [https://pmc.ncbi.nlm.nih.gov/articles/PMC7332158/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7332158/)   
22. [https://pmc.ncbi.nlm.nih.gov/articles/PMC11132164/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11132164/)   
23. [https://www.bmj.com/content/375/bmj-2021-067487](https://www.bmj.com/content/375/bmj-2021-067487)   
24. [https://pmc.ncbi.nlm.nih.gov/articles/PMC11933818/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11933818/)   
   
The medical concept of triage—rapidly assessing and prioritizing patients based on the severity and urgency of their conditions—offers a powerful metaphor for approaching the deepfake crisis. Just as emergency departments triage patients to ensure the most critical cases receive immediate care, we must triage information to protect health equity and public safety during crises.   
Organizations like Meedan's Digital Health Lab have pioneered the application of public health risk frameworks to health misinformation online, developing systems to prioritize responses based on potential harm and negative impacts. This approach recognizes that not all misinformation requires equal response—some false claims pose immediate dangers requiring expert consultation, while others can be addressed through general public health messaging or digital literacy interventions.[meedan](https://meedan.com/post/strategies-for-triaging-responses-to-health-misinformation-online-a)   
But triage is fundamentally a crisis response—a recognition that resources are scarce and perfect outcomes impossible. Our ultimate goal must be more transformative: building information ecosystems resilient enough that they don't require constant emergency intervention.   
This transformation demands several parallel efforts:   
**Investment in Infrastructure:** Societies must invest in the technological, regulatory, and educational infrastructure needed to maintain information integrity. This includes funding for detection technology development, support for fact-checking organizations, resources for digital literacy programs, and mechanisms for international coordination on standards and enforcement.   
**Health Equity at the Center:** Solutions must be designed with equity in mind, ensuring that marginalized communities—who often face both greater exposure to health risks and greater vulnerability to misinformation—have access to detection tools, digital literacy resources, and trusted sources of information. This requires addressing the digital divide, supporting community-based organizations, and centering the voices and experiences of those most affected.   
**Interdisciplinary Collaboration:** The deepfake crisis sits at the intersection of technology, psychology, public health, policy, law, and ethics. Effective responses require sustained collaboration across these disciplines, breaking down silos between academic researchers, technology developers, healthcare providers, policymakers, and community organizers.   
**Protecting the Protectors:** Healthcare workers and other trusted messengers face extraordinary burdens during health emergencies, amplified by the need to combat misinformation while providing care. Systems must be in place to support their mental health, provide them with tools and training, and protect them from the psychological toll of operating on multiple frontlines simultaneously.   
**Cultural Shift:** Ultimately, societies need a cultural shift in how we relate to information—moving from passive consumption to active critical evaluation, from individual skepticism to collective vigilance, from reactive debunking to proactive resilience. This shift requires fostering what might be called "information hygiene"—habitual practices of verification, source-checking, and healthy skepticism that become second nature.   
1. [https://meedan.com/post/strategies-for-triaging-responses-to-health-misinformation-online-a](https://meedan.com/post/strategies-for-triaging-responses-to-health-misinformation-online-a)   
   
On a fundamental level, the deepfake crisis is a deeply human problem. It exploits our psychological tendencies to trust what we see and hear, our need for connection and community, our fears and hopes. The technology may be artificial, but the harm it inflicts is profoundly real—measured in damaged mental health, eroded trust, disrupted healthcare, preventable deaths.   
Seventy-seven-year-old Nikki MacLeod's experience illustrates both the human vulnerability and the human cost. Lonely after losing her parents during the pandemic and experiencing the end of a long-term relationship, she sought connection online. When someone claiming to be "Alla Morgan" sent video messages that appeared genuine, Nikki's initial skepticism dissolved. "I was completely convinced," she later told BBC Scotland. She transferred £17,000 before her bank alerted her to the scam. The criminals continue to contact her, most recently claiming their fictional persona is imprisoned in Turkey and needs more money.[bbc](https://www.bbc.com/news/articles/cdr0g1em52go)   
"These scammers lack any empathy," Nikki reflected. "It's their profession, and they excel at it. The documents, the videos, and even the bank details seemed legitimate. With the rise of artificial intelligence, everything can easily be fabricated".[bbc](https://www.bbc.com/news/articles/cdr0g1em52go)   
Her story reminds us that behind statistics about fraud rates and incident counts are real people—individuals seeking connection, patients seeking health information, healthcare workers seeking to help their communities. The deepfake crisis threatens all of them.   
Yet the same human qualities that make us vulnerable—our capacity for trust, our desire for community, our empathy—also represent our greatest strengths in confronting this crisis. Community-based organizations succeed as trusted messengers precisely because they embody care and commitment. Inoculation interventions work because they tap into our ability to learn and adapt. Healthcare workers continue to show up, even exhausted and embattled, because they're driven by a commitment to healing.   
As we confront this crisis, we must ensure that our responses honor and amplify these human strengths rather than simply reacting to technological vulnerabilities. We must build systems that foster trust rather than merely detect deception, that empower communities rather than simply regulate platforms, that cultivate wisdom rather than simply correct errors.   
The deepfake crisis is, at its core, a test of our collective intelligence—not artificial intelligence, but the deeply human intelligence that allows us to cooperate, to build trust across differences, to prioritize the vulnerable, and to act on evidence even when it challenges our preconceptions. This is the intelligence that has allowed human societies to overcome epidemics, develop vaccines, build public health systems. It's the intelligence we must marshal now, as we work to ensure that even in a world where seeing may no longer mean believing, caring still means healing.   
The stakes could not be higher. But neither could our capacity for response—if we choose to act, together, now.   
 --- 
**About the Author:** Dr. Jamie Forrest is the Scientific Director of the Health Equity & Resilience Observatory (HERO) at the University of British Columbia's Faculty of Applied Science. HERO applies the urgent logic of medical triage to the information chaos of public health emergencies, working to protect information integrity and health equity in the digital age.   
1. [https://www.bbc.com/news/articles/cdr0g1em52go](https://www.bbc.com/news/articles/cdr0g1em52go)   
